{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image path</th>\n",
       "      <th>Class</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/Train/FBO1/cacao-31.jpg</td>\n",
       "      <td>FBO1</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/Train/FBO1/cacao-32.jpg</td>\n",
       "      <td>FBO1</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/Train/FBO1/cacao-33.jpg</td>\n",
       "      <td>FBO1</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/Train/FBO1/cacao-34.jpg</td>\n",
       "      <td>FBO1</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/Train/FBO1/cacao-35.jpg</td>\n",
       "      <td>FBO1</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Image path Class  Weight\n",
       "0  Dataset/Train/FBO1/cacao-31.jpg  FBO1    1.66\n",
       "1  Dataset/Train/FBO1/cacao-32.jpg  FBO1    1.27\n",
       "2  Dataset/Train/FBO1/cacao-33.jpg  FBO1    1.79\n",
       "3  Dataset/Train/FBO1/cacao-34.jpg  FBO1    1.25\n",
       "4  Dataset/Train/FBO1/cacao-35.jpg  FBO1    1.85"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READ CSV WITH IMAGE PATHS\n",
    "\n",
    "train_ds = pd.read_csv(\"../Dataset/labels_train.csv\", index_col=0)\n",
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.measure import regionprops\n",
    "from skimage.measure import label\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from scipy import stats\n",
    "\n",
    "def process_image(image):\n",
    "    \n",
    "    # Resize once and convert to grayscale\n",
    "    image_resized = cv2.resize(image, (500, 300))\n",
    "    image_gray = cv2.cvtColor(image_resized, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Thresholding and hole filling\n",
    "    _, img = cv2.threshold(image_gray, 0, 1, cv2.THRESH_OTSU)\n",
    "    img = 1 - img\n",
    "    img = binary_fill_holes(img)\n",
    "\n",
    "    # Calculate largest bounding box using regionprops\n",
    "    lab, num = label(img, return_num=True)\n",
    "    max_area = 0\n",
    "    bbox = []\n",
    "\n",
    "    for i in range(1, num + 1):\n",
    "        object_region = (lab == i).astype('uint8')\n",
    "        prop = regionprops(object_region)[0]\n",
    "        area = prop.area\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            bbox = prop.bbox\n",
    "\n",
    "            \n",
    "    # If max_area is too small, skip processing (early exit)\n",
    "    if max_area < 1000:\n",
    "        print(f\"Max area too small: {max_area}\")\n",
    "        return None\n",
    "\n",
    "    # Crop the image and apply the mask\n",
    "    img_cropped = image_resized[bbox[0]: bbox[2], bbox[1]: bbox[3]]\n",
    "    mask_cropped = img[bbox[0]: bbox[2], bbox[1]:bbox[3]]\n",
    "    img_cropped = img_cropped * mask_cropped[..., None]\n",
    "\n",
    "    old_image_height, old_image_width, channels = img_cropped.shape\n",
    "\n",
    "    # create new image of desired size and color (blue) for padding\n",
    "    new_image_width = 300\n",
    "    new_image_height = 300\n",
    "    color = (0,0,0)\n",
    "    result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n",
    "\n",
    "    # compute center offset\n",
    "    x_center = (new_image_width - old_image_width) // 2\n",
    "    y_center = (new_image_height - old_image_height) // 2\n",
    "\n",
    "    # copy img image into center of result image\n",
    "    result[y_center:y_center+old_image_height, \n",
    "        x_center:x_center+old_image_width] = img_cropped\n",
    "\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1612/1612 [03:15<00:00,  8.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "labels = []\n",
    "\n",
    "for i in tqdm(range(len(train_ds))):\n",
    "    image = cv2.imread(\"../\" + train_ds.iloc[i][\"Image path\"])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img = process_image(image)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img = cv2.resize(img, (100,100))\n",
    "    \n",
    "    cv2.imwrite(f\"../Dataset/Processed/Train/cacao-{i}.jpg\", img)\n",
    "    labels.append([f\"cacao-{i}.jpg\", train_ds.iloc[i][\"Class\"], train_ds.iloc[i][\"Weight\"]])\n",
    "\n",
    "df = pd.DataFrame(labels, columns=[\"image\", \"class\", \"weight\"])\n",
    "df.to_csv(\"../Dataset/Processed/labels_train.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
